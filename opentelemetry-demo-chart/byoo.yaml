---
# Source: opentelemetry-demo/charts/prometheus/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/version: v2.53.1
    helm.sh/chart: prometheus-25.24.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: otel-demo-prometheus-server
  namespace: apps
  annotations:
    {}
---
# Source: opentelemetry-demo/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-demo
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: otel-demo
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/name: otel-demo
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
---
# Source: opentelemetry-demo/charts/prometheus/templates/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/version: v2.53.1
    helm.sh/chart: prometheus-25.24.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: otel-demo-prometheus-server
  namespace: apps
data:
  allow-snippet-annotations: "false"
  alerting_rules.yml: |
    {}
  alerts: |
    {}
  prometheus.yml: |
    global:
      evaluation_interval: 30s
      scrape_interval: 5s
      scrape_timeout: 3s
    storage:
      tsdb:
        out_of_order_time_window: 30m
    rule_files:
    - /etc/config/recording_rules.yml
    - /etc/config/alerting_rules.yml
    - /etc/config/rules
    - /etc/config/alerts
    scrape_configs:
    - honor_labels: true
      job_name: otel-collector
      kubernetes_sd_configs:
      - namespaces:
          own_namespace: true
        role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_opentelemetry_community_demo
  recording_rules.yml: |
    {}
  rules: |
    {}
---
# Source: opentelemetry-demo/templates/flagd-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: flagd-config
  namespace: apps
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: otel-demo
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/name: otel-demo
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
data:
  
  demo.flagd.json: |
    {
      "$schema": "https://flagd.dev/schema/v0/flags.json",
      "flags": {
        "productCatalogFailure": {
          "description": "Fail product catalog service on a specific product",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "recommendationServiceCacheFailure": {
          "description": "Fail recommendation service cache",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adServiceManualGc": {
          "description": "Triggers full manual garbage collections in the ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adServiceHighCpu": {
          "description": "Triggers high cpu load in the ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "adServiceFailure": {
          "description": "Fail ad service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "kafkaQueueProblems": {
          "description": "Overloads Kafka queue while simultaneously introducing a consumer side delay leading to a lag spike",
          "state": "ENABLED",
          "variants": {
            "on": 100,
            "off": 0
          },
          "defaultVariant": "off"
        },
        "cartServiceFailure": {
          "description": "Fail cart service",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "paymentServiceFailure": {
          "description": "Fail payment service charge requests",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "off"
        },
        "paymentServiceUnreachable": {
          "description": "Payment service is unavailable",
          "state": "ENABLED",
          "variants": {
            "on": true,
            "off": false
          },
          "defaultVariant": "on"
        },
        "loadgeneratorFloodHomepage": {
          "description": "Flood the frontend with a large amount of requests.",
          "state": "ENABLED",
          "variants": {
            "on": 100,
            "off": 0
          },
          "defaultVariant": "off"
        },
        "imageSlowLoad": {
          "description": "slow loading images in the frontend",
          "state": "ENABLED",
          "variants": {
            "10sec": 10000,
            "5sec": 5000,
            "off": 0
          },
          "defaultVariant": "off"
        }
      }
    }
---
# Source: opentelemetry-demo/charts/prometheus/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/version: v2.53.1
    helm.sh/chart: prometheus-25.24.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: otel-demo-prometheus-server
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
      - nodes/proxy
      - nodes/metrics
      - services
      - endpoints
      - pods
      - ingresses
      - configmaps
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - "extensions"
      - "networking.k8s.io"
    resources:
      - ingresses/status
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - "discovery.k8s.io"
    resources:
      - endpointslices
    verbs:
      - get
      - list
      - watch
  - nonResourceURLs:
      - "/metrics"
    verbs:
      - get
---
# Source: opentelemetry-demo/charts/prometheus/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/version: v2.53.1
    helm.sh/chart: prometheus-25.24.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: otel-demo-prometheus-server
subjects:
  - kind: ServiceAccount
    name: otel-demo-prometheus-server
    namespace: apps
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-demo-prometheus-server
---
# Source: opentelemetry-demo/charts/prometheus/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/version: v2.53.1
    helm.sh/chart: prometheus-25.24.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: otel-demo-prometheus-server
  namespace: apps
spec:
  ports:
    - name: http
      port: 9090
      protocol: TCP
      targetPort: 9090
  selector:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: otel-demo
  sessionAffinity: None
  type: "ClusterIP"
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: adservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: adservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: adservice
    app.kubernetes.io/name: adservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: adservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: cartservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: cartservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: cartservice
    app.kubernetes.io/name: cartservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: cartservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: checkoutservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: checkoutservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: checkoutservice
    app.kubernetes.io/name: checkoutservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: checkoutservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: currencyservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: currencyservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: currencyservice
    app.kubernetes.io/name: currencyservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: currencyservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: emailservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: emailservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: emailservice
    app.kubernetes.io/name: emailservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: emailservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: flagd
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: flagd
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: flagd
    app.kubernetes.io/name: flagd
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8013
      name: tcp-service
      targetPort: 8013
  selector:
    
    opentelemetry.io/name: flagd
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: frontend
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: frontend
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: frontend
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontendproxy
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: frontendproxy
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: frontendproxy
    app.kubernetes.io/name: frontendproxy
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: frontendproxy
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: imageprovider
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: imageprovider
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: imageprovider
    app.kubernetes.io/name: imageprovider
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8081
      name: tcp-service
      targetPort: 8081
  selector:
    
    opentelemetry.io/name: imageprovider
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: kafka
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9092
      name: plaintext
      targetPort: 9092
    - port: 9093
      name: controller
      targetPort: 9093
  selector:
    
    opentelemetry.io/name: kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: paymentservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: paymentservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: paymentservice
    app.kubernetes.io/name: paymentservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: paymentservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: productcatalogservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: productcatalogservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: productcatalogservice
    app.kubernetes.io/name: productcatalogservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: productcatalogservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: quoteservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: quoteservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: quoteservice
    app.kubernetes.io/name: quoteservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: quoteservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: recommendationservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: recommendationservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: recommendationservice
    app.kubernetes.io/name: recommendationservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: recommendationservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: shippingservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: shippingservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: shippingservice
    app.kubernetes.io/name: shippingservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: shippingservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: valkey
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: valkey
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: valkey
    app.kubernetes.io/name: valkey
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 6379
      name: valkey
      targetPort: 6379
  selector:
    
    opentelemetry.io/name: valkey
---
# Source: opentelemetry-demo/charts/prometheus/templates/deploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/version: v2.53.1
    helm.sh/chart: prometheus-25.24.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: prometheus
  name: otel-demo-prometheus-server
  namespace: apps
spec:
  selector:
    matchLabels:
      app.kubernetes.io/component: server
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/instance: otel-demo
  replicas: 1
  revisionHistoryLimit: 10
  strategy:
    type: Recreate
    rollingUpdate: null
  template:
    metadata:
      labels:
        app.kubernetes.io/component: server
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/version: v2.53.1
        helm.sh/chart: prometheus-25.24.1
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: prometheus
    spec:
      enableServiceLinks: true
      serviceAccountName: otel-demo-prometheus-server
      containers:

        - name: prometheus-server
          image: "quay.io/prometheus/prometheus:v2.53.1"
          imagePullPolicy: "IfNotPresent"
          args:
            - --storage.tsdb.retention.time=15d
            - --config.file=/etc/config/prometheus.yml
            - --storage.tsdb.path=/data
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --web.console.templates=/etc/prometheus/consoles
            - --enable-feature=exemplar-storage
            - --enable-feature=otlp-write-receiver
          ports:
            - containerPort: 9090
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 5
            timeoutSeconds: 4
            failureThreshold: 3
            successThreshold: 1
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 15
            timeoutSeconds: 10
            failureThreshold: 3
            successThreshold: 1
          resources:
            limits:
              memory: 300Mi
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: storage-volume
              mountPath: /data
              subPath: ""
      dnsPolicy: ClusterFirst
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      terminationGracePeriodSeconds: 300
      volumes:
        - name: config-volume
          configMap:
            name: otel-demo-prometheus-server
        - name: storage-volume
          emptyDir:
            {}
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: accountingservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: accountingservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: accountingservice
    app.kubernetes.io/name: accountingservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: accountingservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: accountingservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: accountingservice
        app.kubernetes.io/name: accountingservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: accountingservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-accountingservice'
          imagePullPolicy: IfNotPresent
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: KAFKA_SERVICE_ADDR
            value: kafka:9092
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 120Mi
          volumeMounts:
      volumes:
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: adservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: adservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: adservice
    app.kubernetes.io/name: adservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: adservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: adservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: adservice
        app.kubernetes.io/name: adservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: adservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-adservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: AD_SERVICE_PORT
            value: "8080"
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318
          - name: OTEL_LOGS_EXPORTER
            value: otlp
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 300Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cartservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: cartservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: cartservice
    app.kubernetes.io/name: cartservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: cartservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: cartservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: cartservice
        app.kubernetes.io/name: cartservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: cartservice
          image: 'localhost:63091/cartservice:local'
          imagePullPolicy: Always
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: CART_SERVICE_PORT
            value: "8080"
          - name: ASPNETCORE_URLS
            value: http://*:$(CART_SERVICE_PORT)
          - name: VALKEY_ADDR
            value: valkey:6379
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              cpu: 25m
              memory: 64Mi
            requests:
              cpu: 25m
              memory: 64Mi
          volumeMounts:
      volumes:
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 valkey 6379; do echo waiting for valkey; sleep 2; done;
          image: busybox:latest
          name: wait-for-valkey
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: checkoutservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: checkoutservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: checkoutservice
    app.kubernetes.io/name: checkoutservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: checkoutservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: checkoutservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: checkoutservice
        app.kubernetes.io/name: checkoutservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: checkoutservice
          image: 'localhost:63091/checkoutservice:local'
          imagePullPolicy: Always
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: CHECKOUT_SERVICE_PORT
            value: "8080"
          - name: CART_SERVICE_ADDR
            value: cartservice:8080
          - name: CURRENCY_SERVICE_ADDR
            value: currencyservice:8080
          - name: EMAIL_SERVICE_ADDR
            value: http://emailservice:8080
          - name: PAYMENT_SERVICE_ADDR
            value: paymentservice:8080
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: productcatalogservice:8080
          - name: SHIPPING_SERVICE_ADDR
            value: shippingservice:8080
          - name: KAFKA_SERVICE_ADDR
            value: kafka:9092
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      volumes:
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: currencyservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: currencyservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: currencyservice
    app.kubernetes.io/name: currencyservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: currencyservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: currencyservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: currencyservice
        app.kubernetes.io/name: currencyservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: currencyservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-currencyservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: CURRENCY_SERVICE_PORT
            value: "8080"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: VERSION
            value: '1.11.1'
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: emailservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: emailservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: emailservice
    app.kubernetes.io/name: emailservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: emailservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: emailservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: emailservice
        app.kubernetes.io/name: emailservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: emailservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-emailservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: EMAIL_SERVICE_PORT
            value: "8080"
          - name: APP_ENV
            value: production
          - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 100Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flagd
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: flagd
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: flagd
    app.kubernetes.io/name: flagd
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: flagd
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: flagd
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: flagd
        app.kubernetes.io/name: flagd
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: flagd
          image: 'ghcr.io/open-feature/flagd:v0.11.1'
          imagePullPolicy: IfNotPresent
          command:
          - /flagd-build
          - start
          - --uri
          - file:./etc/flagd/demo.flagd.json
          - --port
          - "8013"
          ports:
          
          - containerPort: 8013
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: FLAGD_METRICS_EXPORTER
            value: otel
          - name: FLAGD_OTEL_COLLECTOR_URI
            value: $(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 128Mi
          volumeMounts:
            - name: config
              mountPath: /etc/flagd
      volumes:
        - name: config
          configMap:
            name: flagd-config
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frauddetectionservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: frauddetectionservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: frauddetectionservice
    app.kubernetes.io/name: frauddetectionservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: frauddetectionservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: frauddetectionservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: frauddetectionservice
        app.kubernetes.io/name: frauddetectionservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: frauddetectionservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-frauddetectionservice'
          imagePullPolicy: IfNotPresent
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: KAFKA_SERVICE_ADDR
            value: kafka:9092
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 300Mi
          volumeMounts:
      volumes:
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: frontend
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: frontend
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: frontend
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: frontend
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: frontend
        app.kubernetes.io/name: frontend
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: frontend
          image: 'localhost:63091/frontend:local'
          imagePullPolicy: Always
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: FRONTEND_PORT
            value: "8080"
          - name: FRONTEND_ADDR
            value: :8080
          - name: AD_SERVICE_ADDR
            value: adservice:8080
          - name: CART_SERVICE_ADDR
            value: cartservice:8080
          - name: CHECKOUT_SERVICE_ADDR
            value: checkoutservice:8080
          - name: CURRENCY_SERVICE_ADDR
            value: currencyservice:8080
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: productcatalogservice:8080
          - name: RECOMMENDATION_SERVICE_ADDR
            value: recommendationservice:8080
          - name: SHIPPING_SERVICE_ADDR
            value: shippingservice:8080
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: OTEL_COLLECTOR_HOST
            value: $(OTEL_COLLECTOR_NAME)
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: WEB_OTEL_SERVICE_NAME
            value: frontend-web
          - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://localhost:8080/otlp-http/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 250Mi
          securityContext:
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontendproxy
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: frontendproxy
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: frontendproxy
    app.kubernetes.io/name: frontendproxy
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: frontendproxy
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: frontendproxy
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: frontendproxy
        app.kubernetes.io/name: frontendproxy
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: frontendproxy
          image: 'ghcr.io/open-telemetry/demo:1.11.1-frontendproxy'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: ENVOY_PORT
            value: "8080"
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: FRONTEND_HOST
            value: frontend
          - name: FRONTEND_PORT
            value: "8080"
          - name: GRAFANA_SERVICE_HOST
            value: grafana
          - name: GRAFANA_SERVICE_PORT
            value: "80"
          - name: IMAGE_PROVIDER_HOST
            value: imageprovider
          - name: IMAGE_PROVIDER_PORT
            value: "8081"
          - name: JAEGER_SERVICE_HOST
            value: jaeger-query
          - name: JAEGER_SERVICE_PORT
            value: "16686"
          - name: LOCUST_WEB_HOST
            value: loadgenerator
          - name: LOCUST_WEB_PORT
            value: "8089"
          - name: OTEL_COLLECTOR_HOST
            value: $(OTEL_COLLECTOR_NAME)
          - name: OTEL_COLLECTOR_PORT_GRPC
            value: "4317"
          - name: OTEL_COLLECTOR_PORT_HTTP
            value: "4318"
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 50Mi
          securityContext:
            runAsGroup: 101
            runAsNonRoot: true
            runAsUser: 101
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: imageprovider
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: imageprovider
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: imageprovider
    app.kubernetes.io/name: imageprovider
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: imageprovider
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: imageprovider
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: imageprovider
        app.kubernetes.io/name: imageprovider
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: imageprovider
          image: 'ghcr.io/open-telemetry/demo:1.11.1-imageprovider'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8081
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: IMAGE_PROVIDER_PORT
            value: "8081"
          - name: OTEL_COLLECTOR_PORT_GRPC
            value: "4317"
          - name: OTEL_COLLECTOR_HOST
            value: $(OTEL_COLLECTOR_NAME)
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 50Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: kafka
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: kafka
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: kafka
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: kafka
        app.kubernetes.io/name: kafka
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: kafka
          image: 'ghcr.io/open-telemetry/demo:1.11.1-kafka'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 9092
            name: plaintext
          - containerPort: 9093
            name: controller
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: KAFKA_ADVERTISED_LISTENERS
            value: PLAINTEXT://kafka:9092
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318
          - name: KAFKA_HEAP_OPTS
            value: -Xmx400M -Xms400M
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 600Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: paymentservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: paymentservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: paymentservice
    app.kubernetes.io/name: paymentservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: paymentservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: paymentservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: paymentservice
        app.kubernetes.io/name: paymentservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: paymentservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-paymentservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: PAYMENT_SERVICE_PORT
            value: "8080"
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 120Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: productcatalogservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: productcatalogservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: productcatalogservice
    app.kubernetes.io/name: productcatalogservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: productcatalogservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: productcatalogservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: productcatalogservice
        app.kubernetes.io/name: productcatalogservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: productcatalogservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-productcatalogservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: PRODUCT_CATALOG_SERVICE_PORT
            value: "8080"
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: quoteservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: quoteservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: quoteservice
    app.kubernetes.io/name: quoteservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: quoteservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: quoteservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: quoteservice
        app.kubernetes.io/name: quoteservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: quoteservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-quoteservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: QUOTE_SERVICE_PORT
            value: "8080"
          - name: OTEL_PHP_AUTOLOAD_ENABLED
            value: "true"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 40Mi
          securityContext:
            runAsGroup: 33
            runAsNonRoot: true
            runAsUser: 33
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: recommendationservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: recommendationservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: recommendationservice
    app.kubernetes.io/name: recommendationservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: recommendationservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: recommendationservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: recommendationservice
        app.kubernetes.io/name: recommendationservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: recommendationservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-recommendationservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: RECOMMENDATION_SERVICE_PORT
            value: "8080"
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: productcatalogservice:8080
          - name: OTEL_PYTHON_LOG_CORRELATION
            value: "true"
          - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
            value: python
          - name: FLAGD_HOST
            value: flagd
          - name: FLAGD_PORT
            value: "8013"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 500Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: shippingservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: shippingservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: shippingservice
    app.kubernetes.io/name: shippingservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: shippingservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: shippingservice
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: shippingservice
        app.kubernetes.io/name: shippingservice
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: shippingservice
          image: 'ghcr.io/open-telemetry/demo:1.11.1-shippingservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: SHIPPING_SERVICE_PORT
            value: "8080"
          - name: QUOTE_SERVICE_ADDR
            value: http://quoteservice:8080
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 20Mi
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: valkey
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: valkey
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: valkey
    app.kubernetes.io/name: valkey
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      
      opentelemetry.io/name: valkey
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: valkey
        app.kubernetes.io/instance: otel-demo
        app.kubernetes.io/component: valkey
        app.kubernetes.io/name: valkey
    spec:
      serviceAccountName: otel-demo
      containers:
        - name: valkey
          image: 'valkey/valkey:7.2-alpine'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 6379
            name: valkey
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_COLLECTOR_NAME
            value: alloy-k8s-monitoring.monitoring
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: deployment.environment=local
          resources:
            limits:
              memory: 20Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 999
          volumeMounts:
      volumes:
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: cartservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.32.8
    
    opentelemetry.io/name: cartservice
    app.kubernetes.io/instance: otel-demo
    app.kubernetes.io/component: cartservice
    app.kubernetes.io/name: cartservice
    app.kubernetes.io/version: "1.11.1"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: cartservice
  minReplicas: 1
  maxReplicas: 2
  metrics:
    - resource:
        name: cpu
        target:
          averageUtilization: 90
          type: Utilization
      type: Resource
